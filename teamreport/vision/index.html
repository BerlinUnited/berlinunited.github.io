
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.3.6">
    
    
      
        <title>Visual Perception - Berlin United - Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4a0965b7.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cbb835fc.min.css">
        
      
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#visual-perception" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Berlin United - Documentation" class="md-header__button md-logo" aria-label="Berlin United - Documentation" data-md-component="logo">
      
  <img src="../../img/favicon.ico" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Berlin United - Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Visual Perception
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
            </label>
          
        
      </form>
    
    
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../.." class="md-tabs__link">
      Welcome to Berlin United
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../" class="md-tabs__link md-tabs__link--active">
        Teamreport
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../naoth_tools/rc/" class="md-tabs__link">
        Tooling
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../guides/onboarding/" class="md-tabs__link">
        Guides
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Berlin United - Documentation" class="md-nav__button md-logo" aria-label="Berlin United - Documentation" data-md-component="logo">
      
  <img src="../../img/favicon.ico" alt="logo">

    </a>
    Berlin United - Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Welcome to Berlin United
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Teamreport
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Teamreport" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Teamreport
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        Welcome
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../architecture_intro/" class="md-nav__link">
        Architecture
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../debugging/" class="md-nav__link">
        Debugging and Tools
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Visual Perception
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Visual Perception
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#green-detection" class="md-nav__link">
    Green Detection
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scanlineedgeldetector" class="md-nav__link">
    ScanLineEdgelDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fielddetector" class="md-nav__link">
    FieldDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linegraphprovider" class="md-nav__link">
    LineGraphProvider
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ransaclinedetector" class="md-nav__link">
    RansacLineDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goalfeaturedetector" class="md-nav__link">
    GoalFeatureDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goaldetector" class="md-nav__link">
    GoalDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#blackwhite-ball-detection" class="md-nav__link">
    Black&amp;White Ball Detection
  </a>
  
    <nav class="md-nav" aria-label="Black&amp;White Ball Detection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#s:ball:candidate" class="md-nav__link">
    Candidate Search -- Perspective Key Points Detection
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classification" class="md-nav__link">
    Classification
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#acknowledgment" class="md-nav__link">
    Acknowledgment
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/" class="md-nav__link">
        Modeling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../motion/" class="md-nav__link">
        Motion Control
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../behavior/" class="md-nav__link">
        Behavior
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../bibliography/" class="md-nav__link">
        Bibliography
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Tooling
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tooling" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Tooling
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../naoth_tools/rc/" class="md-nav__link">
        RoboControl
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../naoth_tools/naoscp/" class="md-nav__link">
        NaoSCP
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../naoth_tools/xabsleditor/" class="md-nav__link">
        Xabsleditor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../naoth_tools/simspark/" class="md-nav__link">
        Simspark
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../naoth_tools/webots/" class="md-nav__link">
        Webots
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../naoth_tools/gitlab-ci/" class="md-nav__link">
        Gitlab CI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../naoth_tools/lab-trackingsystem/" class="md-nav__link">
        NaoTH Tracking System
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../robocup_tools/" class="md-nav__link">
        RoboCup Project
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../robocup_tools/game_recording/" class="md-nav__link">
        Game Recording
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Guides
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Guides" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Guides
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/onboarding/" class="md-nav__link">
        Joining the team
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2">
          Setup
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Setup" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          Setup
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/setup/naoth_code_setup/" class="md-nav__link">
        NaoTH Development Setup
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/setup/robot_setup/" class="md-nav__link">
        NAO setup and deployment
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/setup/nao_config/" class="md-nav__link">
        Configuration Files
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3">
          Working With Robots
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Working With Robots" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          Working With Robots
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/robot_handling/" class="md-nav__link">
        Handling the Robot
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/robots/known-robot-issues/" class="md-nav__link">
        Known Issues with Robots
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_4" type="checkbox" id="__nav_4_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_4">
          Calibrating Parameters
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Calibrating Parameters" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          Calibrating Parameters
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/calibration/action_selection/" class="md-nav__link">
        Action Selection
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/working-with-logfiles/working-with-logfiles/" class="md-nav__link">
        Working with logfiles
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/working-with-sound/working-with-sound/" class="md-nav__link">
        Sound
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/logging/" class="md-nav__link">
        Logging
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/obstacle_detection/" class="md-nav__link">
        Obstacle Detection and Pathplanning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/keyframe_motions/" class="md-nav__link">
        Keyframe Motions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/other_teams/" class="md-nav__link">
        Setup code from other teams
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_11" type="checkbox" id="__nav_4_11" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_11">
          Code Conventions
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Code Conventions" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_11">
          <span class="md-nav__icon md-icon"></span>
          Code Conventions
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/coding_guidelines/" class="md-nav__link">
        Coding Guidelines
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/git-hooks/" class="md-nav__link">
        Git-Hooks
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_12" type="checkbox" id="__nav_4_12" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_12">
          Deep Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Deep Learning" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_12">
          <span class="md-nav__icon md-icon"></span>
          Deep Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/deeplearning/training/" class="md-nav__link">
        Training Deep Learning Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/deeplearning/data_prep/" class="md-nav__link">
        Data Prep for Deep Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/deeplearning/deep_learning_deployment/" class="md-nav__link">
        How to deploy Tensorflow Models on the Nao
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#green-detection" class="md-nav__link">
    Green Detection
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scanlineedgeldetector" class="md-nav__link">
    ScanLineEdgelDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fielddetector" class="md-nav__link">
    FieldDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linegraphprovider" class="md-nav__link">
    LineGraphProvider
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ransaclinedetector" class="md-nav__link">
    RansacLineDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goalfeaturedetector" class="md-nav__link">
    GoalFeatureDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goaldetector" class="md-nav__link">
    GoalDetector
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#blackwhite-ball-detection" class="md-nav__link">
    Black&amp;White Ball Detection
  </a>
  
    <nav class="md-nav" aria-label="Black&amp;White Ball Detection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#s:ball:candidate" class="md-nav__link">
    Candidate Search -- Perspective Key Points Detection
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classification" class="md-nav__link">
    Classification
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#acknowledgment" class="md-nav__link">
    Acknowledgment
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<div><h1 id="visual-perception">Visual Perception<a class="headerlink" href="#visual-perception" title="Permanent link">¶</a></h1>
<p>Visual perception is the primary way for the NAO robot of perceiving its environment. To reduce computational 
complexity our vision is based on a reliable field color detection. This color information is used to estimate 
the boundaries of the visible field region in the image. Which is done while scanning for 
line edgels - oriented jumps in the brightness channel. Detection of other objects - lines, ball, 
goals - is performed within this field region. Lines are modeled as a graph of the aforementioned edgels. 
Ball detection consists mainly of two steps - key points (ball candidates) are detected using <em>integral image</em> 
and <em>difference of gaussians</em>, which are then  classified by a trained cascade classifier. Goal post detection uses scan lines along the horizon.</p>
<p>The image below shows the dependency graph for the vision
modules and the representations they provide, which were used at the
RoboCup 2016 competition. In the following we describe some of the
important modules in more detail.</p>
<figure>
  <img src="../img/vision-modules.png">
  <figcaption>
Overview over the vision system. Green boxes illustrate modules and
round nodes visualize the representations with arrows indicating the
provide-require relationships between them. 
An outgoing arrow from a module $A$ to a representation $R$ means $A$ provides $R$; an incoming
arrow from $R$ to $A$ means $R$ is required by $A$.</figcaption>
</figure>

<h2 id="green-detection">Green Detection<a class="headerlink" href="#green-detection" title="Permanent link">¶</a></h2>
<p>This section describes a new approach to classify the field color which has been used since late 2015. 
For the first time this approach has been presented in November 2015 at the RoHOW workshop in Hamburg, Germany.
This constitutes the first step in the attempt for a automatic field color detection. Thereby we analyze 
the structure of the color space perceived by the robot NAO and propose a simple yet powerful model for 
separation of the color regions, whereby green color is of a particular interest.</p>
<figure>
  <img src="../img/green_detection.png">
  <figcaption>
(left) Example image from the Iran Open 2015. (right) Pixels
classified as green are marked green; pixels with too low chroma marked
red;
</figcaption>
</figure>

<p>To illustrate our findings we utilize a sequence of images from recorded
by a robot during the Iran Open 2015. The left image above is a representative image from
this sequence. </p>
<p>To analyze the coverage of the color space we calculate
two color histograms over the whole image sequence. In the
Figure <a href="#fig:green-hist">4.6</a>{reference-type="ref"
reference="fig:green-hist"} (left) you can see the uv-histogram, which
is basically a projection of the yuv-space onto the uv-plane. The light
green points indicate the frequency of a particular uv-value (the
brighter the more). One can clearly recognize three different clusters:
white and gray colors in the center; green cluster oriented towards the
origin; and a smaller cluster of blue pixels in the direction of the
u-axis which originate from the boundaries around the field. For the
second histogram we choose a projection plane along the y-axis and
orthogonal to the uv-plane which is illustrated in the
Figure <a href="#fig:green-hist">4.6</a>{reference-type="ref"
reference="fig:green-hist"} (left) by the red line. This plane is chosen
in a way to illuminate the relation between the gray cluster in the
center and the green cluster.
Figure <a href="#fig:green-hist">4.6</a>{reference-type="ref"
reference="fig:green-hist"} (middle) illustrates the resulting
histogram. Here we clearly see the gray and the green cluster.</p>
<figure>
  <img src="../img/green_histogram.png">
  <figcaption>
(left) UV-histogram for a log file taken
at the Iran Open 2015. Red line illustrates the projection plane along
the green region for the Y-Chroma histogram (middle); (middle)
Y-Chroma-histogram along the projection plane illustrated in (left)
figure. Red lines illustrate the gray-cone, i.e., area with not enough
color information to be classified as a particular color; (right)
UV-Histogram without pixel falling into the gray-cone as illustrated in
the (middle) figure. Red lines illustrate the segment to be classified
as green.
</figcaption>
</figure>

<p>From these two histograms we can make following observations: all colors
seem to be concentrically organized around the central brightness axis ,
i.e., gray axis <span class="arithmatex">\((128,128,y)\)</span>, which corresponds to the general
definition of the yuv-space; the colors seem to be pressed closer to the
gray axis the darker they are. In particular all colors below a certain
y-threshold seem to be collapsed to the gray axis. So we can safely
claim that for a pixel <span class="arithmatex">\((y,u,v)\)</span> always holds <span class="arithmatex">\(y=0 \Rightarrow u,v=128\)</span>.
On the contrary the spectrum of colors gets wider with the rising
brightness. Speculatively one could think that the actual space of
available colors is a hsi-cone fitted into the yuv-cube. The collapse of
the colors towards the gray axis might be explained by an underlying
noise reduction procedure of the camera.</p>
<p>Based on these observations we can divide the classification in two
steps: (1) separate the pixels which do not carry enough color
information, i.e., these which are too close to the gray axis.
Figure <a href="#fig:green-hist">4.6</a>{reference-type="ref"
reference="fig:green-hist"} (middle) illustrates a simple segmentation
of the gray pixels with a cone around the center axis illustrated by the
red lines; (2) classify the color in the projection onto the uv-plane.
Figure <a href="#fig:green-hist">4.6</a>{reference-type="ref"
reference="fig:green-hist"} (right) shows the uv-histogram without the
gray pixels. Red lines illustrate the separated uv-segment which is
classified as green. This way we ensure independence from brightness.
The equation <a href="#eq:green">[eq:green]</a>{reference-type="ref"
reference="eq:green"} illustrates the three conditions necessary for a
pixel <span class="arithmatex">\((y,u,v)\)</span> to be classified as green. The five parameter are
<span class="arithmatex">\(b_o\in[0,255]\)</span> the back cut off threshold, <span class="arithmatex">\(b_m, b_M\in [0,128]\)</span> with
<span class="arithmatex">\(b_m&lt;b_M\)</span> the minimal and the maximal radius of the gray cone, and
finally <span class="arithmatex">\(a_m,a_M\in[-\pi, \pi]\)</span> defining the green segment in the
uv-plane.</p>
<div class="arithmatex">\[
\begin{aligned}
(u-128)^2 + (v-128)^2 &amp;&gt; \max\left(b_m, b_m + (b_M - b_m)\cdot\frac{y - b_o}{255 - b_o} \right) \\
\text{atan2}(u-128, v-128) &amp;&gt; a_m \\
\text{atan2}(u-128, v-128) &amp;&lt; a_M
\label{eq:green}
\end{aligned}
\]</div>
<p>The classification itself doesn't require an explicit calculation of
histograms. At the current state it's a static classification depending
on five parameters to define the separation regions for the gray and
green colors. These parameters can be easily adjusted by inspecting the
histograms as shown in the
Figure <a href="#fig:green-hist">4.6</a>{reference-type="ref"
reference="fig:green-hist"} and have proven to be quite robust to local
light variation.</p>
<p>The structure of the color space depends of course largely on the
adjustments of the white balance. We suspect a deviation from a perfect
white balance adjustment results in a tilt of the gray cluster towards
blue region if it's to cool and towards red if it's too warm. The tilt
towards blue can be seen in the
Figure <a href="#fig:green-hist">4.6</a>{reference-type="ref"
reference="fig:green-hist"} (middle). This might be a queue for an
automatic white balance procedure which would ensure an optimal
separation between colored and gray pixels. The green region shifts
around the center depending on the general lighting conditions, color
temperature of the carpet and of course white balance. In the current
example the green tends rather towards the blue region. Tracking these
shifts might be the way for a fully automatic green color classifier
which would be able to cover the variety of the shades to enable a robot
to play outside.</p>
<h2 id="scanlineedgeldetector">ScanLineEdgelDetector<a class="headerlink" href="#scanlineedgeldetector" title="Permanent link">¶</a></h2>
<figure>
  <img src="../img/ScanLineEdgelDetector.png">
  <figcaption>
With top to down scanlines [green lines] the edges of possible
field lines [black lines] including their orientation are detected
(left) and the last field colored points are assumed as endpoints of the
field [green circles] (right).
</figcaption>
</figure>

<p>With this module we detect field line border points and estimate some
points of the field border. To do this, we use scanlines, but only
vertical ones. Along every scanline jumps are detected in the Y channel,
using a 1D-Prewitt-Filter. A point of the field lines border is located
at the maximum of the response of that filter. We estimate with two
3x3-Sobel-Filters (horizontal and vertical) the orientation of the line.
With the result of the field color classification we detect along every
scanline a point, which marks the border of the field.</p>
<h2 id="fielddetector">FieldDetector<a class="headerlink" href="#fielddetector" title="Permanent link">¶</a></h2>
<p>With the field border points, estimated with the
<em>ScanLineEdgelDetector</em>, we calculate for each image a polygon, which is
representing the border of the field in the image.</p>
<figure>
  <img src="../img/field_detector.png">
  <figcaption>
The endpoints provided by the ScanLineEdgelDetector (left) are used
to calculate the field border (right).
</figcaption>
</figure>

<h2 id="linegraphprovider">LineGraphProvider<a class="headerlink" href="#linegraphprovider" title="Permanent link">¶</a></h2>
<p>This module clusters neighbouring line border points, detected by
<em>ScanLineEdgelDetector</em>.</p>
<figure>
  <img src="../img/line_graph_provider.png">
  <figcaption>
TODO: write a caption here
</figcaption>
</figure>

<h2 id="ransaclinedetector">RansacLineDetector<a class="headerlink" href="#ransaclinedetector" title="Permanent link">¶</a></h2>
<p>This module detects lines on the directed points generated by the
LineGraphProvider using the Random sample consensus (RANSAC) method. Our
implementation can be summarized by the following 4 steps.</p>
<ol>
<li>
<p>We pick two random directed points with a similar orientation to
    form a model of the Line. This will be a line candidate.</p>
</li>
<li>
<p>We count the inliers and outliers of the model. A point is marked as
    an inlier, if it is close to the line and has a similar direction.
    We accumulate the error of the distance for later validation.</p>
</li>
<li>
<p>If a model has a sufficient amount of inliers, it may be considered
    as a valid line. We repeat the above steps for a number of
    iterations and continue with the best model according to the amount
    of inliers and the smallest error in distance.</p>
</li>
<li>
<p>Finally, we determine the endpoints of the line. We choose them as
    the maximum and minimum x and y values of the inliers. If the length
    of the line is sufficient, a field line is returned.</p>
</li>
</ol>
<p>In order to detect the remaining field lines we repeat this procedure on
the remaining outliers until no lines are found.</p>
<h2 id="goalfeaturedetector">GoalFeatureDetector<a class="headerlink" href="#goalfeaturedetector" title="Permanent link">¶</a></h2>
<p>This module is the first step of the goal post detection procedure. To
detect the goal posts we scan along the horizontal scan lines parallel
to the artificial horizon estimated in <em>ArtificialHorizonProvider</em>.
Similar to the detection of the field line described in
Section <a href="#s:ScanLineEdgelDetector">4.2</a>{reference-type="ref"
reference="s:ScanLineEdgelDetector"} we detect edgels characterized by
the jumps in the pixel brightness. These edgels are combined pairwise to
goal features, which are essentially horizontal line segments with
rising and falling brightness at the end points.
Figure <a href="#fig:GoalFeatureDetector">4.8</a>{reference-type="ref"
reference="fig:GoalFeatureDetector"} illustrates the scan lines as well
as detected edgels (left) and resulting goal post features (right).</p>
<figure>
  <img src="../img/goal_feature_detector.png">
  <figcaption>
The scan lines [grey lines] above and below the estimated horizon
are used to detect the goal post border points and the orientation of
the corresponding edges [colored and black segments] (left). The
results are features of possible goal posts [blue line segments with
red dots]
(right).
</figcaption>
</figure>

<h2 id="goaldetector">GoalDetector<a class="headerlink" href="#goaldetector" title="Permanent link">¶</a></h2>
<p>The <em>GoalDetector</em> clusters the features found by the
<em>GoalFeatureDetector</em>. The main idea here is, that features, which
represent a goal post, must be located underneath of each other. We
begin with the scan line with the lowest y coordinate and go through all
detected features. Then the features of the next scan lines (next higher
y coordinate) are checked against these features. Features of all scan
lines, which are located underneath of each other, are collected into
one cluster. Each of these clusters represents a possible goal post.</p>
<figure>
  <img src="../img/goal_detector.png">
  <figcaption>
Goal features detected as described in
[4.6](#s:GoalFeatureDetector){reference-type="ref"
reference="s:GoalFeatureDetector"} are clustered to form candidates for
the goal posts (left). These candidates are evaluated regarding expected
dimensions as well as their relation to the field. The candidates
fulfilling all necessary criteria are selected as goal post percepts
(right green boxes).
</figcaption>
</figure>

<p>From the features of a cluster, the orientation of the possible goal
post is estimated and used to scan up and down along the estimated goal
post. This is done to find the foot and the top point of that goal post.
A goal post is seen as valid, if its foot point is inside of the field
polygon as described in the
Section <a href="#s:FieldDetector">4.3</a>{reference-type="ref"
reference="s:FieldDetector"}. Using the kinematic chain the foot point
is projected into the relative coordinates of the robot. Based on this
estimated position the expected dimensions of the post are projected
back into the image. To be accepted as a goal post percept a candidate
cluster has to satisfy those dimensions, i.e., the deviation should not
exceed certain thresholds. The
Figure <a href="#fig:GoalDetector">4.10</a>{reference-type="ref"
reference="fig:GoalDetector"} illustrates the clustering step and the
evaluation of the candidate clusters. Although there seem to be a
considerable amount of false features, both posts of the goal are
detected correctly.</p>
<h2 id="blackwhite-ball-detection">Black&amp;White Ball Detection<a class="headerlink" href="#blackwhite-ball-detection" title="Permanent link">¶</a></h2>
<p>In 2015 the standard ball used in competitions changed to a black&amp;white
foam ball as illustrated in
Figure <a href="#fig:bw-ball">4.13</a>{reference-type="ref"
reference="fig:bw-ball"}. Detection of such a ball in the SPL setup
poses a considerable challenge. In this section we describe our strategy
for detecting a black&amp;white ball in a single image and the lessons
learned.</p>
<p>Given an image from the robot camera the whole approach is basically
divided into two steps: finding a small set of suitable candidates for a
ball by a fast heuristic algorithm, and classifying the candidates
afterwards with a more precise method.</p>
<figure>
  <img src="../img/ball_examples.png">
  <figcaption>
Examples of the black&amp;white as seen by the
robot.
</figcaption>
</figure>

<h3 id="s:ball:candidate">Candidate Search -- Perspective Key Points Detection<a class="headerlink" href="#s:ball:candidate" title="Permanent link">¶</a></h3>
<p>Properties of the ball as an object that can be assumed as known include</p>
<ul>
<li>
<p>it has a fixed size;</p>
</li>
<li>
<p>it has a round shape (symmetrical shape);</p>
</li>
<li>
<p>it is black and white (so it does not contain other colors);</p>
</li>
<li>
<p>the pattern is symmetric;</p>
</li>
</ul>
<p>These properties have some implications on the appearance of the ball in
a camera image:</p>
<ul>
<li>
<p>knowing the pose of the camera we can estimate the balls size in the
    image;</p>
</li>
<li>
<p>it mostly does not contain other colors than black and white (chroma
    is low). Note: beware of reflections;</p>
</li>
<li>
<p>looking only at the color distribution we can assume it's rotation
    invariant;</p>
</li>
</ul>
<p>Having the limited computational resources in mind, we are looking now
for following three things:</p>
<ol>
<li>
<p>a simple object representation for a ball in image;</p>
</li>
<li>
<p>an effective and easy to calculate measure quantifying the
    likelihood such object to represent an actual ball;</p>
</li>
<li>
<p>a tractable algorithm to find a finite set of local minimas of this
    measure over a given image (these minimal elements we then call
    candidates);</p>
</li>
</ol>
<h5 id="representation">Representation:<a class="headerlink" href="#representation" title="Permanent link">¶</a></h5>
<p>In our case we define a <em>ball candidate</em> (more general a <em>key point</em>) as
a square region in the image which is likely to contain a ball. Such a
key point <span class="arithmatex">\(c = (x,y,r)\)</span> can be described by its position in the image
<span class="arithmatex">\((x,y)\)</span> and its side radius (half side length) <span class="arithmatex">\(r\)</span>. Basically we
represent a circular object by the outer square (bounding box) enclosing
the circle. This leads to a vast number of possible candidates in a
single image and a necessity for an efficient heuristic algorithm to
find the most likely ones.</p>
<h5 id="measure">Measure:<a class="headerlink" href="#measure" title="Permanent link">¶</a></h5>
<p>Intuitively described, a <em>good</em> key point is much brighter inside than
on its outer border. For a key point <span class="arithmatex">\(c = (x,y,r)\)</span> we define its
<em>intensity value</em> <span class="arithmatex">\(I(c)\)</span> by</p>
<div class="arithmatex">\[I(c): = \frac{1}{4r^2}\sum_{i,j = x-r}^{x+r} Y(i,j)\]</div>
<p>where <span class="arithmatex">\(Y(j,i)\)</span>
is the <span class="arithmatex">\(Y\)</span>-channel value of the image at the pixel <span class="arithmatex">\((i,j)\)</span>. For the
intensity of the outer border around <span class="arithmatex">\(c\)</span> with the width <span class="arithmatex">\(\delta &gt; 0\)</span>
holds <span class="arithmatex">\(I(c_\delta) - I(c)\)</span>, with <span class="arithmatex">\(c_\delta:= (x,y,r\cdot(1+\delta))\)</span>.
Now we can formulate the measure for <span class="arithmatex">\(c\)</span> by</p>
<div class="arithmatex">\[V(c): = I(c) - (I(c_\delta) - I(c)) = 2\cdot I(c) - I(c_\delta)\]</div>
<p>This measure function can be calculated very effectively using integral
images. Figure <a href="#fig:bw-patch-function">4.17</a>{reference-type="ref"
reference="fig:bw-patch-function"} (left) illustrates the measure
function for the valid pixels of the image.</p>
<h5 id="finding-the-local-maxima">Finding the local maxima:<a class="headerlink" href="#finding-the-local-maxima" title="Permanent link">¶</a></h5>
<p>To save resources the search is performed only within the estimated
field region (cf. Section <a href="#s:FieldDetector">4.3</a>{reference-type="ref"
reference="s:FieldDetector"}). For a given point <span class="arithmatex">\(p = (i,j)\)</span> in image we
estimate the radius <span class="arithmatex">\(r_b(i,j)\)</span> that the ball would have at this point in
the image using the camera matrix. This estimated radius is used to
calculate the measure function at this point:
<span class="arithmatex">\(V(p):= V((i,j,r_b(i,j)))\)</span>. Currently we only consider points at which
the ball would be completely inside the image. The following algorithm
illustrates how the local maxima of this function are estimated:</p>
<figure>
  <img src="../img/local_maxima_algorithm.png">
  <figcaption>
</figcaption>
</figure>

<p>The basic idea is to keep only the key points with higher value than any
other overlapping key points, i.e., the one with the highest value in
it's neighborhood. To generate the list of <em>possible key points</em> we
iterate over the image and generate key points for each pixel. Of course
a number of heuristics is used to make the process tractable. In
particular we only consider every 4th pixel and only if it is within the
estimated field region. The list of local maxima is also limited to 5
elements - the list is kept sorted and any additional key points with
lower value are discarded.</p>
<p>Figure <a href="#fig:bw-patch-function">4.17</a>{reference-type="ref"
reference="fig:bw-patch-function"} (right) and
Figure <a href="#fig:bw-patches">4.21</a>{reference-type="ref"
reference="fig:bw-patches"} illustrate the detected best 5 local maxima
of the measure function.</p>
<figure>
  <img src="../img/key_points.png">
  <figcaption>
  Illustration of the value function for finding the ball key points.
Semitransparent overlay illustrates the searched area. Intensity of the
red color shows the value
function.
</figcaption>
</figure>

<figure>
  <img src="../img/patches.png">
  <figcaption>
  Illustration of detected key points in the situations where the ball
is close to the robot or overlapping with the line.
</figcaption>
</figure>

<h3 id="classification">Classification<a class="headerlink" href="#classification" title="Permanent link">¶</a></h3>
<p>In the previous section we discussed how the number of possible ball
candidates can be efficiently reduced. At the current state we consider
about 5 candidates per image. In general these candidates look very ball
alike, e.g., hands or feet of the robots, and cannot be easily
separated. To solve this we follow the approach of supervised learning,
which mainly involves collecting positive and negative samples, and
training a classifier. In the following we outline our approach for fast
collection of the sample data and give some brief remarks about our
experience with the OpenCV Cascade Classifier which we used during the
RoboCup competition in 2016.</p>
<h4 id="sample-data-generation">Sample Data Generation<a class="headerlink" href="#sample-data-generation" title="Permanent link">¶</a></h4>
<p>Collecting sample data basically involves two steps: collecting images
from game situations and labeling the ones containing the ball. This can
be a very tedious and time consuming task. To simplify and accelerate
the process we collect only the candidate patches calculated by the
algorithm in Section <a href="#s:ball:candidate">4.8.1</a>{reference-type="ref"
reference="s:ball:candidate"}. This allows to collect the data during a
competition game at full frame rate. This however produces a vast amount
of data to be labeled. Because the patches are quite small (we
experimented with sizes between <span class="arithmatex">\(12px\times 12px\)</span> and
<span class="arithmatex">\(24px\times 24px\)</span>), a large number of patches can be presented and
reviewed at once.
Figure <a href="#fig:bw-ball-labeling">4.23</a>{reference-type="ref"
reference="fig:bw-ball-labeling"} illustrates two examples of the
labeling interface. Patches are presented in pages consisting of a
<span class="arithmatex">\(10\times10\)</span> matrix. Labels can be applied or removed simply by clicking
with the mouse at a particular patch.</p>
<figure>
  <img src="../img/old_label_tool.png">
  <figcaption>
  Examples of the labeling interface. Patches are presented in pages
consisting of a $10\times10$ matrix. Labels are applied or removed by a
mouse click at a particular
patch.
</figcaption>
</figure>

<h4 id="classification-with-convolutional-neural-networks">Classification with Convolutional Neural Networks<a class="headerlink" href="#classification-with-convolutional-neural-networks" title="Permanent link">¶</a></h4>
<p>In the last step the generated ball candidates (patches) are classified.
At the current point we distinguish two classes: <code>ball</code> and <code>noball</code>. As
a classifier we use a Convolutional Neural Network (CNN). The weights of
the network are trained in MatLab with the help of the <em>Neural Network
Toolbox</em>. The resulting network is exported with our custom export
function <code>createCppFile.m</code> to optimized hard coded implementation of the
network in C++. The generated files are included in the project and
directly used by the ball detector. All corresponding functions can be
found in the directory <code>Utils\MatlabDeepLearning</code>. Example of the
resulting classification can be found in .</p>
<figure>
  <img src="../img/detected_ball.png">
  <figcaption>
Examples of the detected
ball.
</figcaption>
</figure>

<h3 id="acknowledgment">Acknowledgment<a class="headerlink" href="#acknowledgment" title="Permanent link">¶</a></h3>
<p>Some of the most important parts of this ball detection procedure were
inspired by very fruitful discussions with the RoboCup community. At
this point we would like to thank in particular the team NaoDevils for
providing their trained CNN classifier during the RoboCup 2017
competition. This classifier is included in our code base and can be
used for comparison purposes. It can be found in\
<code>...\VisualCortex\BallDetector\Classifier\DortmundCNN</code>.</p></div>

              
            </article>
            
          </div>
        </div>
        
      </main>
      
        

<!-- Footer -->
<footer class="md-footer">

  <!-- The base theme links to previous and/or next page, we omit that here. -->

  <!-- Further information -->
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">

      <!-- Copyright and theme information -->
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>

      <!-- Social links -->
      <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/naoteamhumboldt" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://github.com/BerlinUnited" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://www.youtube.com/user/teamhumboldt" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://www.instagram.com/naoteamhumboldt" target="_blank" rel="noopener" title="www.instagram.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"/></svg>
    </a>
  
</div>
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "toc.follow"], "search": "../../assets/javascripts/workers/search.85cb4492.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.a877e258.min.js"></script>
      
        <script src="../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>